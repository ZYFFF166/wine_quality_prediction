 import numpy as np
import pandas as pd
from time import time
from IPython.display import display 
import matplotlib.pyplot as plt
data = pd.read_csv("data/winequality-white.csv", sep=';')
display(data.head(n=5))
data.dtypes

sep=[1,5,6,10]
class_label=[0,1,2]
data['quality_class'] = pd.cut(data['quality'], bins=sep, labels=class_label, include_lowest=True)
data["class_predict"]=[9999 for i in range(data.shape[0])]
display(data.head(n=10))
# Split the data into features and target label

quality_raw = data['quality_class']
features_raw = data.drop(['quality'], axis = 1)
#sub=data[data["quality_class"]==0]
#print(sub.shape[0])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(features_raw, quality_raw, test_size = 0.1, random_state = 0)
#print(type(X_train))
# Show the results of the split
#print("Training set has {} samples.".format(X_train.shape[0]))
#print("Testing set has {} samples.".format(X_test.shape[0]))
#print("XT:")
#print(X_test.head(5))
headers=[column for column in X_train]
print(headers)

def prob_single_attr(num,attr_name):
    prob=((X_train[X_train[attr_name]==num].shape[0])+1)/(X_train.shape[0])
    return prob
#print(prob_single_attr(0,'quality_class'))

def prob_2_attr(num1,name1,num2,name2):
    temp=X_train[X_train[name2]==num2]
    prob=((X_train[(X_train[name1]==num1) & (X_train[name2]==num2)].shape[0])+1)/(temp.shape[0])
    return prob
#print(prob_2_attr(7.0,'fixed acidity',0,'quality_class'))

def naiveBayesianClassifier(X_train, X_test, y_train, y_test):
    
    for index, row in X_test.iterrows():
        item=row.tolist()
        prob_0=(prob_2_attr(item[0],headers[0],0,headers[11]) * prob_2_attr(item[1],headers[1],0,headers[11]) * \
                prob_2_attr(item[2],headers[2],0,headers[11]) * prob_2_attr(item[3],headers[3],0,headers[11]) * \
                prob_2_attr(item[4],headers[4],0,headers[11]) * prob_2_attr(item[5],headers[5],0,headers[11]) * \
                prob_2_attr(item[6],headers[6],0,headers[11]) * prob_2_attr(item[7],headers[7],0,headers[11]) * \
                prob_2_attr(item[8],headers[8],0,headers[11]) * prob_2_attr(item[9],headers[9],0,headers[11]) * \
                prob_2_attr(item[10],headers[10],0,headers[11]) * prob_single_attr(0,headers[11])) /(prob_single_attr(item[0],headers[0]) * \
                                                         prob_single_attr(item[1],headers[1]) * \
                 prob_single_attr(item[2],headers[2]) * prob_single_attr(item[3],headers[3]) * \
                prob_single_attr(item[4],headers[4]) * prob_single_attr(item[5],headers[5]) * \
                prob_single_attr(item[6],headers[6]) * prob_single_attr(item[7],headers[7]) * \
                prob_single_attr(item[8],headers[8]) * prob_single_attr(item[9],headers[9]) * \
                prob_single_attr(item[10],headers[10]) )
        prob_1=(prob_2_attr(item[0],headers[0],1,headers[11]) * prob_2_attr(item[1],headers[1],1,headers[11]) * \
                prob_2_attr(item[2],headers[2],1,headers[11]) * prob_2_attr(item[3],headers[3],1,headers[11]) * \
                prob_2_attr(item[4],headers[4],1,headers[11]) * prob_2_attr(item[5],headers[5],1,headers[11]) * \
                prob_2_attr(item[6],headers[6],1,headers[11]) * prob_2_attr(item[7],headers[7],1,headers[11]) * \
                prob_2_attr(item[8],headers[8],1,headers[11]) * prob_2_attr(item[9],headers[9],1,headers[11]) * \
                prob_2_attr(item[10],headers[10],1,headers[11]) * prob_single_attr(1,headers[11])) /(prob_single_attr(item[0],headers[0]) * \
                                                         prob_single_attr(item[1],headers[1]) * \
                 prob_single_attr(item[2],headers[2]) * prob_single_attr(item[3],headers[3]) * \
                prob_single_attr(item[4],headers[4]) * prob_single_attr(item[5],headers[5]) * \
                prob_single_attr(item[6],headers[6]) * prob_single_attr(item[7],headers[7]) * \
                prob_single_attr(item[8],headers[8]) * prob_single_attr(item[9],headers[9]) * \
                prob_single_attr(item[10],headers[10]) )
        prob_2=(prob_2_attr(item[0],headers[0],2,headers[11]) * prob_2_attr(item[1],headers[1],2,headers[11]) * \
                prob_2_attr(item[2],headers[2],2,headers[11]) * prob_2_attr(item[3],headers[3],2,headers[11]) * \
                prob_2_attr(item[4],headers[4],2,headers[11]) * prob_2_attr(item[5],headers[5],2,headers[11]) * \
                prob_2_attr(item[6],headers[6],2,headers[11]) * prob_2_attr(item[7],headers[7],2,headers[11]) * \
                prob_2_attr(item[8],headers[8],2,headers[11]) * prob_2_attr(item[9],headers[9],2,headers[11]) * \
                prob_2_attr(item[10],headers[10],2,headers[11]) * prob_single_attr(2,headers[11])) /(prob_single_attr(item[0],headers[0]) * \
                                                         prob_single_attr(item[1],headers[1]) * \
                 prob_single_attr(item[2],headers[2]) * prob_single_attr(item[3],headers[3]) * \
                prob_single_attr(item[4],headers[4]) * prob_single_attr(item[5],headers[5]) * \
                prob_single_attr(item[6],headers[6]) * prob_single_attr(item[7],headers[7]) * \
                prob_single_attr(item[8],headers[8]) * prob_single_attr(item[9],headers[9]) * \
                prob_single_attr(item[10],headers[10]) )
        if prob_0 < prob_1:
            if prob_1 < prob_2:
                data.loc[index,"class_predict"]=2
            else:
                data.loc[index,"class_predict"]=1
        else:
            if prob_0 < prob_2:
                data.loc[index,"class_predict"]=2
            else:
                data.loc[index,"class_predict"]=0
    return X_test
start_time=time()
naiveBayesianClassifier(X_train, X_test, y_train, y_test)
end_time=time()
time_cost=end_time-start_time
print(data[data["class_predict"]!=9999].head(10))

#output matrix of results on testing set
result=data[data["class_predict"]!=9999]
confusion_matrix={"predict_0":[0,0,0] , "predict_1":[0,0,0] , "predict_2":[0,0,0]}
print("Confusion matrix:")
print("Predict_0: actual_0,actual_1,actual_2")
print(result[(result["class_predict"]==0 ) & (result["quality_class"]==0 )].shape[0], end=',')
print(result[(result["class_predict"]==0 ) & (result["quality_class"]==1 )].shape[0],end=',')
print(result[(result["class_predict"]==0 ) & (result["quality_class"]==2 )].shape[0])
print("Predict_1: actual_0,actual_1,actual_2")
print(result[(result["class_predict"]==1 ) & (result["quality_class"]==0 )].shape[0], end=',')
print(result[(result["class_predict"]==1 ) & (result["quality_class"]==1 )].shape[0],end=',')
print(result[(result["class_predict"]==1 ) & (result["quality_class"]==2 )].shape[0])
print("Predict_2: actual_0,actual_1,actual_2")
print(result[(result["class_predict"]==2 ) & (result["quality_class"]==0 )].shape[0], end=',')
print(result[(result["class_predict"]==2 ) & (result["quality_class"]==1 )].shape[0],end=',')
print(result[(result["class_predict"]==2 ) & (result["quality_class"]==2 )].shape[0])
acc=result[result["class_predict"]==result["quality_class"]].shape[0]*100/X_test.shape[0]
print("Accuracy: {:.2f} %".format(acc))
print("Time cost: {} seconds.".format(time_cost))
